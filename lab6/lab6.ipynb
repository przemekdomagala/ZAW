{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5922fb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2  \n",
    "import scipy.ndimage.filters as filters\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from pm import plot_matches\n",
    "\n",
    "fontanna1 = cv2.imread('fontanna1.jpg')\n",
    "fontanna2 = cv2.imread('fontanna2.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3725b84",
   "metadata": {},
   "source": [
    "# Implementacja metody Harrisa 6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3135a13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def h_value(grayscale_image, sobel_size, gauss_size):\n",
    "    sobel_x = cv2.Sobel(grayscale_image, cv2.CV_32F, 1, 0, ksize=sobel_size)\n",
    "    sobel_y = cv2.Sobel(grayscale_image, cv2.CV_32F, 0, 1, ksize=sobel_size)\n",
    "    \n",
    "    # iloczyny pochodnych kierunkowych\n",
    "    Ixx = sobel_x * sobel_x\n",
    "    Iyy = sobel_y * sobel_y\n",
    "    Ixy = sobel_x * sobel_y\n",
    "    \n",
    "    # rozmycie filtrem Gaussa\n",
    "    Ixx = cv2.GaussianBlur(Ixx, (gauss_size, gauss_size), 0)\n",
    "    Iyy = cv2.GaussianBlur(Iyy, (gauss_size, gauss_size), 0)\n",
    "    Ixy = cv2.GaussianBlur(Ixy, (gauss_size, gauss_size), 0)\n",
    "\n",
    "    # obliczenie wartości H\n",
    "    K = 0.05\n",
    "    h = (Ixx * Iyy - Ixy * Ixy) - K * (Ixx + Iyy) ** 2\n",
    "    h = cv2.normalize(h, None, 0, 1, cv2.NORM_MINMAX, cv2.CV_32F)\n",
    "    return h\n",
    "\n",
    "def find_max ( image , size , threshold ) : # size - maximum filter mask size\n",
    "    data_max = filters . maximum_filter ( image , size )\n",
    "    maxima = ( image == data_max )\n",
    "    diff = image > threshold\n",
    "    maxima [ diff == 0] = 0\n",
    "    return np.nonzero( maxima )\n",
    "\n",
    "def draw_stars(image, coordinates):\n",
    "    plt.figure()\n",
    "    plt.imshow(image)\n",
    "    for coord in zip(*coordinates):\n",
    "        plt.plot(\n",
    "            coord[1], coord[0], \"*\", color=\"r\"\n",
    "        )\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c68cbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.55\n",
    "\n",
    "fontanna1_gray = cv2.cvtColor(fontanna1, cv2.COLOR_BGR2GRAY)\n",
    "fontanna2_gray = cv2.cvtColor(fontanna2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "h1 = h_value(fontanna1_gray, 7, 7)\n",
    "h2 = h_value(fontanna2_gray, 7, 7)\n",
    "\n",
    "corners1 = find_max(h1, 7, threshold)\n",
    "corners2 = find_max(h2, 7, threshold)\n",
    "\n",
    "draw_stars(fontanna1, corners1)\n",
    "draw_stars(fontanna2, corners2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ae927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "budynek1 = cv2.imread('budynek1.jpg')\n",
    "budynek2 = cv2.imread('budynek2.jpg')\n",
    "\n",
    "budynek1_gray = cv2.cvtColor(budynek1, cv2.COLOR_BGR2GRAY)\n",
    "budynek2_gray = cv2.cvtColor(budynek2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "h3 = h_value(budynek1_gray, 7, 7)\n",
    "h4 = h_value(budynek2_gray, 7, 7)\n",
    "\n",
    "corners3 = find_max(h3, 7, threshold)\n",
    "corners4 = find_max(h4, 7, threshold)\n",
    "\n",
    "draw_stars(budynek1, corners3)\n",
    "draw_stars(budynek2, corners4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e18cfc",
   "metadata": {},
   "source": [
    "# Deskrypcja 6.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2546ff72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_region(image, coordinates, size):\n",
    "    pts = list(filter(lambda x: x[0] >= size and x[0] < image.shape[0] - size \n",
    "                      and x[1] >= size and x[1] < image.shape[1] - size, zip(coordinates[0], coordinates[1])))\n",
    "    patches = []\n",
    "    for pt in pts:\n",
    "        patch = image[pt[0]-size:pt[0]+size+1, pt[1]-size:pt[1]+size+1]\n",
    "        patches.append(patch.flatten())\n",
    "    return list(zip(patches, pts))\n",
    "\n",
    "def compare_patches(desc1, desc2, n):\n",
    "    comparison = []\n",
    "\n",
    "    for v1, pts1 in desc1:\n",
    "        min_val = float('inf')\n",
    "        best_val = None\n",
    "        for v2, pts2 in desc2:\n",
    "            diff = sum(abs(v1 - v2))\n",
    "            if diff < min_val:\n",
    "                min_val = diff\n",
    "                best_val = [pts1, pts2, diff]\n",
    "\n",
    "        comparison.append(best_val)\n",
    "\n",
    "    comparison.sort(key=lambda x: x[2])\n",
    "    comparison = comparison[:n]\n",
    "\n",
    "    return comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4232764e",
   "metadata": {},
   "source": [
    "### fontanna1, fontanna2, budynek1, budynek2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cffaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 15\n",
    "n = 20\n",
    "\n",
    "def f1f2b1b262():\n",
    "    patches1 = describe_region(fontanna1_gray, corners1, patch_size)\n",
    "    patches2 = describe_region(fontanna2_gray, corners2, patch_size)\n",
    "    similar_patches = compare_patches(patches1, patches2, n)\n",
    "    plot_matches(fontanna1_gray, fontanna2_gray, similar_patches)\n",
    "\n",
    "    patches3 = describe_region(budynek1_gray, corners3, patch_size)\n",
    "    patches4 = describe_region(budynek2_gray, corners4, patch_size)\n",
    "\n",
    "    similar_patches2 = compare_patches(patches3, patches4, n)\n",
    "    plot_matches(budynek1_gray, budynek2_gray, similar_patches2)\n",
    "\n",
    "f1f2b1b262()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a5469b",
   "metadata": {},
   "source": [
    "### fontanna_pow, fontanna1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ab5e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fpowf162():\n",
    "    fontanna_pow = cv2.imread('fontanna_pow.jpg')\n",
    "    fontanna_pow_gray = cv2.cvtColor(fontanna_pow, cv2.COLOR_BGR2GRAY)\n",
    "    h5 = h_value(fontanna_pow_gray, 7, 7)\n",
    "    corners5 = find_max(h5, 7, threshold)\n",
    "\n",
    "    patches5 = describe_region(fontanna_pow_gray, corners5, patch_size)\n",
    "    patches6 = describe_region(fontanna1_gray, corners1, patch_size)\n",
    "\n",
    "    similar_patches3 = compare_patches(patches5, patches6, n)\n",
    "    plot_matches(fontanna_pow_gray, fontanna1_gray, similar_patches3)\n",
    "\n",
    "fpowf162()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d08747",
   "metadata": {},
   "source": [
    "### eiffel1, eiffel2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19673eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def e1e262():\n",
    "    eiffel1 = cv2.imread('eiffel1.jpg')\n",
    "    eiffel2 = cv2.imread('eiffel2.jpg')\n",
    "\n",
    "    eiffel1_gray = cv2.cvtColor(eiffel1, cv2.COLOR_BGR2GRAY)\n",
    "    eiffel2_gray = cv2.cvtColor(eiffel2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    h6 = h_value(eiffel1_gray, 7, 7)\n",
    "    h7 = h_value(eiffel2_gray, 7, 7)\n",
    "\n",
    "    corners6 = find_max(h6, 7, threshold)\n",
    "    corners7 = find_max(h7, 7, threshold)\n",
    "\n",
    "    patches7 = describe_region(eiffel1_gray, corners6, patch_size)\n",
    "    patches8 = describe_region(eiffel2_gray, corners7, patch_size)\n",
    "\n",
    "    similar_patches4 = compare_patches(patches7, patches8, n)\n",
    "    plot_matches(eiffel1_gray, eiffel2_gray, similar_patches4)\n",
    "\n",
    "e1e262()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d0cce6",
   "metadata": {},
   "source": [
    "# afiniczne zmiany jasności"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae14abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_region(image, coordinates, size):\n",
    "    pts = list(filter(lambda x: x[0] >= size and x[0] < image.shape[0] - size \n",
    "                      and x[1] >= size and x[1] < image.shape[1] - size, zip(coordinates[0], coordinates[1])))\n",
    "    patches = []\n",
    "    for pt in pts:\n",
    "        patch = image[pt[0]-size:pt[0]+size+1, pt[1]-size:pt[1]+size+1]\n",
    "        patch = patch.flatten()\n",
    "        mean = np.mean(patch)\n",
    "        std = np.std(patch)\n",
    "        patch = (patch - mean) / std\n",
    "        patches.append(patch)\n",
    "    return list(zip(patches, pts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc55078",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1f2b1b262()\n",
    "fpowf162()\n",
    "e1e262()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a5b75d",
   "metadata": {},
   "source": [
    "# 6.3 Implementacja elementów algorytmu ORB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a7635d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def orb_matching(image_path1, image_path2, n_features=500):\n",
    "    def detect_fast_keypoints(image):\n",
    "        fast = cv2.FastFeatureDetector_create(threshold=25, nonmaxSuppression=True)\n",
    "        keypoints = fast.detect(image, None)\n",
    "        return keypoints\n",
    "\n",
    "    def compute_harris_measure(image, keypoints):\n",
    "        harris_response = cv2.cornerHarris(image, blockSize=2, ksize=3, k=0.04)\n",
    "        for kp in keypoints:\n",
    "            x, y = int(kp.pt[0]), int(kp.pt[1])\n",
    "            kp.response = harris_response[y, x]\n",
    "        return keypoints\n",
    "\n",
    "    def non_maximum_suppression(keypoints, radius=3):\n",
    "        if not keypoints:\n",
    "            return []\n",
    "        \n",
    "        keypoints = sorted(keypoints, key=lambda x: x.response, reverse=True)\n",
    "        suppressed = []\n",
    "        for i, kp in enumerate(keypoints):\n",
    "            keep = True\n",
    "            for j in range(len(suppressed)):\n",
    "                if cv2.norm(kp.pt, suppressed[j].pt) < radius:\n",
    "                    keep = False\n",
    "                    break\n",
    "            if keep:\n",
    "                suppressed.append(kp)\n",
    "        return suppressed\n",
    "\n",
    "    def filter_keypoints_by_patch(keypoints, image_shape, patch_size=31):\n",
    "        margin = patch_size // 2\n",
    "        return [\n",
    "            kp for kp in keypoints\n",
    "            if margin <= kp.pt[0] < image_shape[1] - margin and margin <= kp.pt[1] < image_shape[0] - margin\n",
    "        ]\n",
    "\n",
    "    def compute_orb_descriptors(image, keypoints):\n",
    "        orb = cv2.ORB_create(nfeatures=n_features)\n",
    "        keypoints, descriptors = orb.compute(image, keypoints)\n",
    "        return keypoints, descriptors\n",
    "\n",
    "    # Load images\n",
    "    image1 = cv2.imread(image_path1, cv2.IMREAD_GRAYSCALE)\n",
    "    image2 = cv2.imread(image_path2, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    if image1 is None or image2 is None:\n",
    "        print(\"Error loading images.\")\n",
    "        return\n",
    "\n",
    "    # Process image 1\n",
    "    keypoints1 = detect_fast_keypoints(image1)\n",
    "    keypoints1 = compute_harris_measure(image1, keypoints1)\n",
    "    keypoints1 = non_maximum_suppression(keypoints1)\n",
    "    keypoints1 = filter_keypoints_by_patch(keypoints1, image1.shape, patch_size=31)\n",
    "    keypoints1, descriptors1 = compute_orb_descriptors(image1, keypoints1)\n",
    "\n",
    "    # Process image 2\n",
    "    keypoints2 = detect_fast_keypoints(image2)\n",
    "    keypoints2 = compute_harris_measure(image2, keypoints2)\n",
    "    keypoints2 = non_maximum_suppression(keypoints2)\n",
    "    keypoints2 = filter_keypoints_by_patch(keypoints2, image2.shape, patch_size=31)\n",
    "    keypoints2, descriptors2 = compute_orb_descriptors(image2, keypoints2)\n",
    "\n",
    "    # Match descriptors\n",
    "    matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = matcher.match(descriptors1, descriptors2)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "    # Visualize results\n",
    "    result = cv2.drawMatches(image1, keypoints1, image2, keypoints2, matches[:50], None, flags=2)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.imshow(result)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a867190",
   "metadata": {},
   "outputs": [],
   "source": [
    "orb_matching('fontanna1.jpg', 'fontanna2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cee0c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "orb_matching('budynek1.jpg', 'budynek2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b48f305",
   "metadata": {},
   "outputs": [],
   "source": [
    "orb_matching('eiffel1.jpg', 'eiffel2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ca81d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "orb_matching('eiffel_rot.jpg', 'eiffel2.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5916ed2",
   "metadata": {},
   "source": [
    "# 6.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672fc2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_panorama = cv2.imread('left_panorama.jpg')\n",
    "right_panorama = cv2.imread('right_panorama.jpg')\n",
    "\n",
    "left_panorama_gray = cv2.cvtColor(left_panorama, cv2.COLOR_BGR2GRAY)\n",
    "right_panorama_gray = cv2.cvtColor(right_panorama, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "ORB = cv2.ORB_create()\n",
    "\n",
    "keypoints1, descriptors1 = ORB.detectAndCompute(left_panorama_gray, None)\n",
    "keypoints2, descriptors2 = ORB.detectAndCompute(right_panorama_gray, None)\n",
    "\n",
    "kp_img_left = cv2.drawKeypoints(left_panorama_gray, keypoints1, None, color=(0, 0, 255))\n",
    "kp_img_right = cv2.drawKeypoints(right_panorama_gray, keypoints2, None, color=(0, 0, 255))\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(kp_img_left)\n",
    "plt.title('Keypoints in Left Panorama')\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(kp_img_right)\n",
    "plt.title('Keypoints in Right Panorama')\n",
    "plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a00139",
   "metadata": {},
   "outputs": [],
   "source": [
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING)\n",
    "\n",
    "matches = bf.knnMatch(descriptors1, descriptors2, k=2)\n",
    "good_matches = []\n",
    "for m, n in matches:\n",
    "    if m.distance < 0.5* n.distance:\n",
    "        good_matches.append([m])\n",
    "\n",
    "img_matches = cv2.drawMatchesKnn(left_panorama_gray, keypoints1, right_panorama_gray, keypoints2, good_matches, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(img_matches)\n",
    "plt.title('Matches between Panoramas')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b384ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "keypointsL = np.float32([kp.pt for kp in keypoints1])\n",
    "keypointsR = np.float32([kp.pt for kp in keypoints2])\n",
    "\n",
    "ptsA = np.float32([keypointsL[m[0].queryIdx] for m in good_matches])\n",
    "ptsB = np.float32([keypointsR[m[0].trainIdx] for m in good_matches])\n",
    "\n",
    "homography_matrix, status = cv2.findHomography(ptsA, ptsB, cv2.RANSAC, 5.0)\n",
    "\n",
    "result = cv2.warpPerspective(left_panorama, homography_matrix, (left_panorama.shape[1] + right_panorama.shape[1], right_panorama.shape[0]))\n",
    "\n",
    "result[0:right_panorama.shape[0], 0:right_panorama.shape[1]] = right_panorama\n",
    "\n",
    "result = result[:, :1280]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad29ec61",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(1, 3, figsize=(15, 10))\n",
    "plt.subplot(131)\n",
    "plt.imshow(left_panorama)\n",
    "plt.title('Left panorama')\n",
    "plt.subplot(132)\n",
    "plt.imshow(right_panorama)\n",
    "plt.title('Right panorama')\n",
    "plt.subplot(133)\n",
    "plt.imshow(result)\n",
    "plt.title('Stitched panorama')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
